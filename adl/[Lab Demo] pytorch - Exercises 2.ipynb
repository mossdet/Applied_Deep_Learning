{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKbRyQcPJIvy"
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://www.ucalgary.ca/themes/ucalgary/ucws_theme/images/UCalgary.svg\" width='30%'>\n",
    "</center>\n",
    "\n",
    "[comment]: <> (The following line is for the LECTURE title)\n",
    "<p style=\"text-align:left;\"><font size='6'><b> Deep Learning - Lab </b></font></p>\n",
    "\n",
    "[comment]: <> (The following line is for the TOPIC of the week)\n",
    "<p style=\"text-align:left;\"><font size='4'><b> Pytorch Exercises Part 2 </b></font></p>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpO8Fkc8JSLh"
   },
   "source": [
    "Hello! after successfuly completing the first part of this exercise you should be ready to head in to this collaborative lab armed with some decent insight into the building blocks for an MLP. We'll stick with dense layers for now and keep building our knowledge base until we're comfortable before moving on to more advanced architectures in the next few modules.\n",
    "\n",
    "In this lab we'll look at:\n",
    "\n",
    "- Revisitng simple data.\n",
    "- Visually manifesting our decision boundaries.\n",
    "- Moving on to more complex data, and begginging to tackle multi-class problems.\n",
    "\n",
    "\\\n",
    "\n",
    "\n",
    "For now let's refresh our memory. Right now you should be able to:\n",
    "\n",
    "- take simple data and convert to tensor with ease.\n",
    "- Solve a binary classification problem intuitively and with Pytorch's Linear API.\n",
    "\n",
    "## Part 1\n",
    "\n",
    "\n",
    "Given the above and your previous exercise let's revisit the XOR problem. First of all go ahead and do the follwing:\n",
    "\n",
    "- Define your data.\n",
    "- Define your bround truths.\n",
    "- convert all of the above to tensor and convert to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1,0], [1, 1]])\n",
    "gates = {'OR': np.array([0,1,1,1]),\n",
    "         'AND': np.array([0,0,0,1]),\n",
    "         'XOR': np.array([0,1,1,0])}\n",
    "\n",
    "Xt = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(gates['XOR']).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "torch.Size([4])\n",
      "torch.Size([40000, 2])\n",
      "torch.Size([40000])\n"
     ]
    }
   ],
   "source": [
    "print(Xt.shape)\n",
    "print(y.shape)\n",
    "\n",
    "nr_samples = 10000\n",
    "Xt = np.concatenate([Xt]*nr_samples, axis=0)\n",
    "y = np.concatenate([y]*nr_samples, axis=0)\n",
    "\n",
    "X_train_T = torch.from_numpy(Xt).float()\n",
    "y_train_T = torch.from_numpy(y)\n",
    "\n",
    "X_valid_T = torch.from_numpy(Xt).float()\n",
    "y_valid_T = torch.from_numpy(y)\n",
    "\n",
    "X_test_T = torch.from_numpy(Xt).float()\n",
    "y_test_T = torch.from_numpy(y)\n",
    "\n",
    "print(X_train_T.shape)\n",
    "print(y_train_T.shape)\n",
    "\n",
    "# y = np.tile(y, (2,))\n",
    "\n",
    "# for i in np.arange(len(Xt)):\n",
    "#     print(f\"{Xt[i]} = {y[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTR3BUwxOU-N"
   },
   "source": [
    "OK great! We have everything we need to work with for now so let's plug in what we've learn into some new concepts.\n",
    "\n",
    "##Part 2\n",
    "\n",
    "Pytorch has a pretty lucid object oriented interface, and I've provided the core of th class definiton you need below. Let's go ahead and plug in some dense layers give what we learnt about the `nn.Linear` module in the last session. For this round let's fall back on the configuration that uses the following:\n",
    "\n",
    "- A one dimensional output.\n",
    "- A single Rectified Linear Unit.\n",
    "- Two hidden neurons should be enough but feel free to experiment here.\n",
    "- Feel free to call the class whatever you'd like!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1642678291387,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "EkxCWn9LQQum",
    "outputId": "03b6fc65-3683-434f-b047-6cd148740787"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500\"\n",
       "            height=\"300\"\n",
       "            src=\"https://drive.google.com/file/d/12r-yy2lYIpn4v0ULf8jFMDygPyKaNGSj/preview\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x14b09ac23d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='https://drive.google.com/file/d/12r-yy2lYIpn4v0ULf8jFMDygPyKaNGSj/preview', width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "avhDu73uQavG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(input_dim, 4)\n",
    "        self.out = nn.Linear(4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden_layer1(x))\n",
    "        x = F.softmax(self.out(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCIxP20-STXU"
   },
   "source": [
    "Let's take a look at what's going on here:\n",
    "\n",
    "- Notice on initialization the super constructir is called. This is simply because we're employing `nn.Linear` from `nn.Module` and that particular superclass need to be initalissed in order to become available within our custom class.\n",
    "\n",
    "- The real flexibility of this methodology lies in the fact that we can define our layers as objects and later chop and change, add Nonlinearities etc in the forward pass.\n",
    "\n",
    "##Part 3\n",
    "\n",
    "Before we discuss further however go ahead and:\n",
    "\n",
    "- initialize your new network class given what you know about OOP.\n",
    "- pass in our data.\n",
    "\n",
    "**Hint**\n",
    "\n",
    "- within the core code I gave you we require both `input_dim` and `num_classes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06815868"
   },
   "source": [
    "## Set the Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712714073653,
     "user": {
      "displayName": "Jaskirat Bhatia",
      "userId": "02843885821026967307"
     },
     "user_tz": 420
    },
    "id": "821ae7f4",
    "outputId": "a3fcd0d9-b98e-429b-ce9e-68490a222856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (hidden_layer1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (out): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(X_train_T.shape[1],2)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "CE_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "epochs  = 100\n",
    "loss_hist = np.zeros((epochs,))\n",
    "accuracy_hist = np.zeros((epochs,))\n",
    "y_train_T = y_train_T.type(torch.LongTensor)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_pred = model(X_train_T)\n",
    "    loss = CE_loss(y_pred, y_train_T)\n",
    "    loss_hist[epoch] = loss.item()\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_T)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test_T).type(torch.FloatTensor)\n",
    "        accuracy_hist[epoch] = correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2ydP1O0Z9vs"
   },
   "source": [
    "Awesome! Let's not stop here and keep building on what we know.\n",
    "\n",
    "Now this data is super simple. No noise, four points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1642681381444,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "SU_CYMGGX8ka",
    "outputId": "9a8a3832-fcd2-452f-a8da-c5e94514a3cf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoQUnAsZeCMA"
   },
   "source": [
    "Given that let's go ahead and put together a simple loader with Pytorch's  DataLoader class. For now we'll shy away from any need for normalization or augmentation given the simplicity of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu40BNOqeQ38"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "train = data_utils.TensorDataset(Xt,y)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train , batch_size=1 , shuffle=True)\n",
    "train_loaderb4 = data_utils.DataLoader(train , batch_size=4 , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1642684049823,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "6ECGI3mJeXR9",
    "outputId": "eccef7d7-67fd-4579-f5e8-5cee756d7bef"
   },
   "outputs": [],
   "source": [
    "print('batch: 1\\n')\n",
    "\n",
    "for batch_idx,(data , labels) in enumerate(train_loader):\n",
    "  print(f'input {batch_idx}: {data}, target: {labels}')\n",
    "\n",
    "print('\\nbatch: 4\\n')\n",
    "\n",
    "for batch_idx,(data , labels) in enumerate(train_loaderb4):\n",
    "  print(f'input {batch_idx}: {data}, target: {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C84igjXpmc5H"
   },
   "source": [
    "Now looking at our data loaders here it's easy to see how we might be able to go about intercepting out training data and pushing it through a forward pass, where epochs represent a complete forward and backward pass through the entire datset.\n",
    "\n",
    "\n",
    "\n",
    "##Part 4\n",
    "\n",
    "Before we go ahead and begin to add loss and backpropogation into our training loop - Given the description above go ahead and use the data loader to feed what we have into ourn model.\n",
    "\n",
    "**Note** Notice I've got you on your feet with the first of you nested loops here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1642684881322,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "yD74l3gheYNf",
    "outputId": "70db5fa8-c9b0-4dde-e09b-11eecbf2d563"
   },
   "outputs": [],
   "source": [
    "num_epochs = 700\n",
    "for i in range(0, num_epochs):\n",
    "  ###your code here###\n",
    "\n",
    "\n",
    "print(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdjNC9xupmGF"
   },
   "source": [
    "Great! We're getting somewhere but we're not learning anything. You'll recall from your previous sessions that this is where all of the magic comes into play! Let's take this step by step:\n",
    "\n",
    "- Recall that the first port of call here is to calculate our loss. Note that we're sticking with a simple hidden layer wrappped in a Relu non-linearity and there `nn.MSELoss` will suffice\n",
    "\n",
    "\\\n",
    "\n",
    "\\begin{align}\n",
    "MSE =  \\frac{{1}}{n}  \\sum_{i}^{n} (  y_i-\\hat{y_i})^2\n",
    "\\end{align}\n",
    "\n",
    "\\\n",
    "\n",
    "It's also not uncommon here to keep track of our current loss as a printout or with tensorboard but let's keep things simple for now.\n",
    "\n",
    "- Second of all we're going to need to reset the gradients we're keeping a track of with `optimizer.zero_grad()` lest we accmulate. Note here that we're using Adam as it's great out of the box and efficient but there'll be more on optimizers in a later session. For now let's experiment with changing our learning rate achives.\n",
    "\n",
    "- `loss.backward()` will then calculate our partial derivates for the loss function with regards to all the parameters of our network.\n",
    "\n",
    "\n",
    "- Last of all `optimizer.step()` then peforms our parameter update given our optmizer of choice and the learning rate that we've dialled in.\n",
    "\n",
    "##Part 5\n",
    "\n",
    "Ok ok, now you have the foundations of a training loop and a forward pass let's go ahead and stich it together with what we know conceptually about backpropogating our error. As a refresher we need:\n",
    "\n",
    "- Our part 4 nested training loop.\n",
    "- our loss function, `nn.MSELoss` in this scenario.\n",
    "- reset our gradients with `optimizer.zero_grad()`\n",
    "-Finally calculate our partial derivates with `loss.backward` and update finally apply our parameter updates with `optimizer.step()`\n",
    "\n",
    "Over to you. You've got this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26038,
     "status": "ok",
     "timestamp": 1642692453180,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "EG2gzyNa0xB2",
    "outputId": "e4dacc56-ab85-44aa-c1e6-d3b3245faf33"
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# class Net(nn.Module):\n",
    "\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1642692458474,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "lxY-FjYaFpr7",
    "outputId": "e18e3e68-370e-4a18-f56c-ac070f2fb19f"
   },
   "outputs": [],
   "source": [
    "print(np.where(outputs.detach().cpu().numpy() > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc1c9d7gtMo3"
   },
   "source": [
    "##Part 6\n",
    "\n",
    "Now let's do all of this with the sigmoid outputs we put together in the last exercise in conjunction with `nn.BCELoss`\n",
    "\n",
    "\\\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\theta)\n",
    "&= -\\frac{1}{n}\\sum_{i=1}^n\\sum_{j=1}^m y_{ij}\\log(p_{ij}) \\\\\n",
    "&= -\\frac{1}{n}\\sum_{i=1}^n \\left[y_i \\log(p_i) + (1-y_i) \\log(1-p_i)\\right]\n",
    "\\end{align}\n",
    "\n",
    "\\\n",
    "\n",
    "At this point you should be more than confident to construct this whole thing by yourself so go forward to be the Deep Learning superheroes you were always meant to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1642765120265,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "rg4HmWDi7pof",
    "outputId": "55ed70df-d228-4f43-e5f7-a009bc327b78"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "  print('using gpu!')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('using cpu!')\n",
    "\n",
    "#or\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#check = torch.load('/content/check.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5224,
     "status": "ok",
     "timestamp": 1642763248077,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "vAYU6gs3t0AI",
    "outputId": "6dfbf097-1331-4423-a352-b04d8052c78a"
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "model = run(7000)\n",
    "\n",
    "model.eval()\n",
    "pred = model(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1642763252785,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "sKspYfkBGIMA",
    "outputId": "f945b0dc-a635-4d56-cf8d-5b1fc977d80a"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(np.where(pred.detach().cpu().numpy() > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir0o0JjfukSt"
   },
   "source": [
    "You did it! Now the real beauty of using a sigmoid output with Binary Scrossentropy here is that we're essentially outputting the probability that we're getting closer to a positive class. To really get a sense of this lets manifets our decison boundary. I've supplied all the code you need here simply plug and play your model ensuring that:\n",
    "\n",
    "- `pt` is set to `True`\n",
    "- `output_class` is `False`\n",
    "- Simply pass your model, data and targets and let's see what we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1m1Jm6r600b"
   },
   "source": [
    "---\n",
    "\n",
    "End of Notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbp2DnBr4qvl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def plot_decision(X,y,model,size =(8,8),\n",
    "                  output_class = False,\n",
    "                  pt = False, device='cpu',\n",
    "                  text_pred=False,\n",
    "                  softmax=False):\n",
    "\n",
    "  h = .02  # step size in the mesh\n",
    "\n",
    "  x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "  y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                      np.arange(y_min, y_max, h))\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=size)\n",
    "\n",
    "  if pt:\n",
    "    model.eval()\n",
    "\n",
    "    input = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float().to(device)\n",
    "    outputs = model(input)\n",
    "    if softmax:\n",
    "      outputs = outputs.data.max(1, keepdim=True)[1]\n",
    "    Z = outputs.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    Xt = torch.from_numpy(X).to(device).float()\n",
    "    pred = model(Xt)\n",
    "\n",
    "    if not softmax:\n",
    "      pred = np.where(pred.detach().cpu().numpy() > 0.5, 1, 0).flatten()\n",
    "    else:\n",
    "      pred  =  pred.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "  else:\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "  if output_class:\n",
    "    Z = Z >0.5\n",
    "\n",
    "  # Put the result into a color plot\n",
    "  Z = Z.reshape(xx.shape)\n",
    "  ax.contourf(xx, yy, Z)\n",
    "  ax.axis('on')\n",
    "\n",
    "  # Plot test points\n",
    "  ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "  if text_pred:\n",
    "    plt.title(f'pred: {pred}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1642763410575,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "jOMqjXGj5Ib9",
    "outputId": "a0b31156-720e-4cdf-b34f-810805ef4a1a"
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "plot_decision(Xt.numpy(),y.numpy(),model,output_class = False, pt = True, text_pred=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r4Dbfzw4SNQ"
   },
   "source": [
    "#Extracurriclar\n",
    "\n",
    "Notice in my answer I've created a simple function in order to be able to re-use the training loop in conjunction with evaluation. What's missing right now however is a couple of concepts we're yet to discuss.\n",
    "\n",
    "- Should we need to validate our data during a run with more complex data we're going to need to switch our model to evaluation mode `model.eval()` in order to halt any learning. We'll then need to toggle `model.train()` in order to continue  calculating updating our parameters.\n",
    "\n",
    "- Now is also a good time to discuss the devices available to us. Run the snippet below and see what you get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1642762195907,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "_mBNPfu0-Y_p",
    "outputId": "23ef8397-d81d-4584-cc28-f07421162cc1"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "  print('using gpu!')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('using cpu!')\n",
    "\n",
    "#or\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tRlZP3r-fz4"
   },
   "source": [
    "As you can see I have a GPU available after selecting the appropriate option in the `Runtime - Change runtime type - Hardware accelarator` menu above. While the appropriate CUDA drivers for your local discrete NVIDIA GPU, or cloud instance would be present in a different setup.\n",
    "\n",
    "Given this let's ensure that are model and appropriate data is moved to device for that extra speedup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1642762196664,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "XJQ_wDL5FgpZ",
    "outputId": "239aa266-c035-4393-8730-c9326e6d4b2d"
   },
   "outputs": [],
   "source": [
    "Xt = Xt.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "#Note that printing the tensor here will see it tagged with Cuda as the device\n",
    "print(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8804,
     "status": "ok",
     "timestamp": 1642762206657,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "V9bIiJioC3AM",
    "outputId": "9d212324-7ea6-456a-f671-ebe0d90a0be2"
   },
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(Xt,y)\n",
    "train_loaderb4 = data_utils.DataLoader(train , batch_size=4 , shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "def run(num_epochs, learning_rate=0.01, bench=True):\n",
    "  model = Net(2,1)\n",
    "  model = model.to(device) #to GPU\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  start = time.time()\n",
    "\n",
    "  for i in range(0, num_epochs):\n",
    "    for batch_idx,(data , labels) in enumerate(train_loaderb4):\n",
    "      outputs = model(data)\n",
    "      loss = criterionCE(outputs , labels.unsqueeze(1))\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "  torch.cuda.synchronize()\n",
    "  end = time.time()\n",
    "\n",
    "  if bench:\n",
    "    print(f'training completed in {end-start}s')\n",
    "\n",
    "  return model\n",
    "\n",
    "model = run(7000)\n",
    "\n",
    "model.eval()\n",
    "pred = model(Xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_lEwdj9GqaQ"
   },
   "source": [
    "Note that we're actually seeing a significant hit in terms of training time here as we're not only dealing with the overhead of moving between devices but we're also dealing with small tensors. Parallel computation really shines the deeper we get and the larger our dataset as we'll see in upcoming sessions.\n",
    "\n",
    "Fo now go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "executionInfo": {
     "elapsed": 5735,
     "status": "ok",
     "timestamp": 1642763198309,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "lmXiiQVB2Gdk",
    "outputId": "f989d457-ce2f-4e7c-bd29-22212c67632e"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "\n",
    "for i in range (30):\n",
    "  clear_output(wait=True)\n",
    "  model = run(i, learning_rate=0.1, bench=False)\n",
    "  model.eval()\n",
    "\n",
    "\n",
    "\n",
    "  plot_decision(Xt.cpu().numpy(),y.cpu().numpy(),model,\n",
    "                  output_class=False,\n",
    "                  pt = True)\n",
    "  time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlhEqf1_vSpT"
   },
   "source": [
    "##Final challenges\n",
    "\n",
    "Alright! We've made it so let's head over to our final challenge and get this thing done.\n",
    "\n",
    "###Part 1\n",
    "\n",
    "solve a binary classification problem once more with new data. Note a few things here:\n",
    "\n",
    "- I've already provided you with a make moons example and your respective splits, feel free however to hav a play around with the settings.\n",
    "\n",
    "- You're tasked here with preparing your data for training, and moving to device should you wish.\n",
    "\n",
    "- Finally utilize the plot fucntion I've provided for you. Bonus points if you can demonstrate the shift in decision boundary with increased epoch once again. This one looks pretty cool as the boundary bends to encapsulate each moon.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1642773767578,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "6VBLtP4ZvsNs",
    "outputId": "33a7fb55-301d-4673-e750-09bff8132585"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples = 1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "plt.scatter(X_test[:,0], X_test[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmN4X9vhv6YI"
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 19096,
     "status": "ok",
     "timestamp": 1642773793488,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "wg9nCBiwfhu1",
    "outputId": "9a8a0371-3ac7-48b0-b87e-3be675cf8ea5"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "for i in range (30):\n",
    "  clear_output(wait=True)\n",
    "  model = run(i, learning_rate=0.01,bench=False)\n",
    "  plot_decision(X_test,y_test,model, output_class=False, pt = True, device='cuda')\n",
    "  time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUJDV8NlwEhB"
   },
   "source": [
    "###Part 2\n",
    "\n",
    "Now this is where we test your investigative skills. You have everything you need to begin to deduce how to piece together more complex scenarios so let's step it up a little here.\n",
    "\n",
    "Here I've provided you with an arbitrary number of blobs. You're tasked given what you know about the output of our networks so far to create something a little different. Hints, and clues are as follows:\n",
    "\n",
    "\\\n",
    "\n",
    "- Recall that we've been using a sigmoid output `torch.sigmoid` with an output dimension of 1, giving us a probability that we're looking at our positive class. This time around we'll need a softmax output\n",
    "\\\n",
    "\\\n",
    "\\begin{align}\n",
    "{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n",
    "\\end{align}\n",
    "\\\n",
    "Where we're hoping to receive an output in the shape of **(batch size, number of classes)**. Recall from your previous sessions that the predictions for each class here sum to 1, where we're hoping to squeeze a the closest match to our target class to the highest probability in the given output.\n",
    "\\\n",
    "In short, the number of classes in your expected output shape is a big old clue as to the confifuration of your network's output.\n",
    "\n",
    "- Note also that we're going to be falling back on `nn.CrossEntropyLoss()` as our loss here and - as a hint towards how your network should look - A softmax activation is included and therefore does not need to be included in your network.\n",
    "\n",
    "- Once again finish up by plotting the result and bonus points for decision boundary evolution. Note importantly here however that `softmax` in `plot_decision` should be toggled to `True`. I've done all the legwork for you in the function and we'll discuss what's going on after the boundaries are successfully manifested.\n",
    "\n",
    "- Last of all note that this time our labels do not need to be  unsqueezed.\n",
    "\n",
    "Over to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9JfUJcTyMPY"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, random_state=8, centers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iChSX_GFoFT-"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1642774944100,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "cXWCmaHwmUpB",
    "outputId": "3b58b012-689f-4fd4-89ca-b34222a8b609"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5iFCHM-mrMW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "###your code here###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 23874,
     "status": "ok",
     "timestamp": 1642775348702,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "CecGVfe-pCTq",
    "outputId": "6dc7f1d8-7694-4aa4-fed7-6239d77412bf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "for i in range (30):\n",
    "  clear_output(wait=True)\n",
    "  model = run(i, learning_rate=0.01,bench=False)\n",
    "  plot_decision(X_test,y_test,model, pt = True, device='cuda', softmax=True)\n",
    "  time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lbXTXwHCnRq"
   },
   "source": [
    "Wonderful work! Once again we can see the flexibility of our networks in conjunction with both non-linearities along with tuning the complexity of our network.\n",
    "\n",
    "Recall that we discussed earlier before the challenge that our output is **(batch size, n classes)**. Take a look at the `plot_decision` fucntion after softmax is toggled on. In order to be able to grab the predicted class we need to grab the index of the maximum value for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1642775815233,
     "user": {
      "displayName": "Rhys Williams",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhIFFxOIFUp5vHAqfmGqBcZuGms-xgg6K-EIz5n=s64",
      "userId": "11848860578168838838"
     },
     "user_tz": 0
    },
    "id": "wvQ2n_c0CkAm",
    "outputId": "8a67ed5f-1ea7-48d9-a429-094d3469525a"
   },
   "outputs": [],
   "source": [
    "outputs = model(torch.from_numpy(X_test).float().to(device))\n",
    "print(outputs.shape)\n",
    "pred = outputs.data.max(1, keepdim=True)[1].flatten()\n",
    "print(pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "el--KKUQErNt"
   },
   "source": [
    "Et viola! Perfect we've covered a lot this session but we should all be good to dive into the excitement of literature review, and head on a journey through computer vision!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
